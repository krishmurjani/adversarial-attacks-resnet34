{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11768836,"sourceType":"datasetVersion","datasetId":7388461}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Adversarial Attack on ResNet-34 Image Classifier\n\nThis notebook implements an adversarial attack against a pre-trained ResNet-34 model. The goal is to generate imperceptible perturbations to images that cause the model to misclassify them, particularly focusing on removing the true class from the top-5 predictions.\n\n## Setup and Imports\n\nThe following cell imports necessary libraries and sets up the computing device (CPU or GPU).","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\nimport numpy as np\nimport os\nimport shutil\nimport json\nfrom tqdm import tqdm\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\nimport torch.nn as nn\nfrom torchvision import transforms\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Load the pre-trained ResNet-34 model\nmodel = torchvision.models.resnet34(weights='IMAGENET1K_V1')\nmodel = model.to(device)\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T18:49:19.554715Z","iopub.execute_input":"2025-05-13T18:49:19.554967Z","iopub.status.idle":"2025-05-13T18:49:31.668746Z","shell.execute_reply.started":"2025-05-13T18:49:19.554941Z","shell.execute_reply":"2025-05-13T18:49:31.668067Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n100%|██████████| 83.3M/83.3M [00:00<00:00, 160MB/s] \n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (4): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (5): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)"},"metadata":{}}],"execution_count":1},{"cell_type":"markdown","source":"## Data Preprocessing\n\nSetting up necessary normalization parameters and transformations for the image data. The preprocessing pipeline converts images to tensors and normalizes them according to ImageNet statistics. We also define the paths for our original and adversarial datasets.","metadata":{}},{"cell_type":"code","source":"# Set up normalization parameters\nmean_norms = np.array([0.485, 0.456, 0.406])\nstd_norms = np.array([0.229, 0.224, 0.225])\n\n# Create the transform pipeline\npreprocess = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean_norms, std=std_norms)\n])\n\n# Define dataset paths\ndataset_path = \"/kaggle/input/testdata/TestDataSet\"\nadversarial_path = \"./AdversarialTestSet2\"\n\n# Clear and recreate adversarial directory to prevent duplicates\nif os.path.exists(adversarial_path):\n    shutil.rmtree(adversarial_path)\nos.makedirs(adversarial_path, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T18:49:31.669420Z","iopub.execute_input":"2025-05-13T18:49:31.669809Z","iopub.status.idle":"2025-05-13T18:49:31.675238Z","shell.execute_reply.started":"2025-05-13T18:49:31.669789Z","shell.execute_reply":"2025-05-13T18:49:31.674238Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Custom Dataset Loader\n\nCreating a custom dataset class that handles image loading from folders with proper class labels. This implementation doesn't rely on PyTorch's ImageFolder but creates a similar functionality to have more control over the dataset handling.","metadata":{}},{"cell_type":"code","source":"# Load the dataset using SimpleImageFolder class\nclass SimpleImageFolder(torch.utils.data.Dataset):\n    def __init__(self, root, transform=None):\n        self.transform = transform\n        self.samples = []\n        self.classes = []\n        self.class_to_idx = {}\n        \n        # Get all valid directories\n        class_dirs = [d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d)) and not d.startswith('.')]\n        class_dirs.sort()\n        \n        # For each directory, find all images\n        for i, class_dir in enumerate(class_dirs):\n            self.classes.append(class_dir)\n            self.class_to_idx[class_dir] = i\n            \n            dir_path = os.path.join(root, class_dir)\n            for img_file in os.listdir(dir_path):\n                if img_file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff')):\n                    img_path = os.path.join(dir_path, img_file)\n                    self.samples.append((img_path, i))\n        \n        print(f\"Loaded {len(self.samples)} images across {len(self.classes)} classes\")\n    \n    def __len__(self):\n        return len(self.samples)\n    \n    def __getitem__(self, idx):\n        img_path, label = self.samples[idx]\n        \n        # Open image with PIL and convert to RGB\n        img = Image.open(img_path).convert('RGB')\n        \n        if self.transform:\n            img = self.transform(img)\n        \n        return img, label, img_path\n\ndataset = SimpleImageFolder(dataset_path, transform=preprocess)\ndataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T18:49:31.677447Z","iopub.execute_input":"2025-05-13T18:49:31.677926Z","iopub.status.idle":"2025-05-13T18:49:32.446644Z","shell.execute_reply.started":"2025-05-13T18:49:31.677906Z","shell.execute_reply":"2025-05-13T18:49:32.445972Z"}},"outputs":[{"name":"stdout","text":"Loaded 500 images across 100 classes\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"## Class Mapping\n\nLoading or creating a mapping from folder names to ImageNet class indices. This mapping allows us to correctly evaluate the model's performance by associating our dataset's folder structure with the pre-trained model's class indices.","metadata":{}},{"cell_type":"code","source":"# Load class mapping\ntry:\n    with open('folder_to_class_mapping.json', 'r') as f:\n        folder_to_class = json.load(f)\n        folder_to_class = {k: int(v) for k, v in folder_to_class.items()}\n        print(f\"Loaded mapping for {len(folder_to_class)} folders from file\")\nexcept:\n    print(\"Creating mapping from folder names to ImageNet classes...\")\n    folder_names = dataset.classes\n    \n    folder_to_class = {}\n    for i, folder in enumerate(folder_names):\n        folder_to_class[folder] = 401 + i\n    \n    # Save the mapping for future use\n    with open('folder_to_class_mapping.json', 'w') as f:\n        json.dump(folder_to_class, f)\n    \n    print(f\"Created mapping for {len(folder_to_class)} folders\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T18:49:32.447558Z","iopub.execute_input":"2025-05-13T18:49:32.447843Z","iopub.status.idle":"2025-05-13T18:49:32.454623Z","shell.execute_reply.started":"2025-05-13T18:49:32.447816Z","shell.execute_reply":"2025-05-13T18:49:32.453863Z"}},"outputs":[{"name":"stdout","text":"Creating mapping from folder names to ImageNet classes...\nCreated mapping for 100 folders\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## Enhanced PGD Attack Implementation\n\nThis implements an enhanced version of the Projected Gradient Descent (PGD) attack with momentum. The attack is specifically tailored to remove the true class from the model's top-5 predictions, making it particularly effective for top-5 evasion. Key features include:\n\n- Momentum-based gradient updates to overcome local minima\n- Custom loss function targeting top-5 evasion\n- Gradient normalization for stability\n- Proper handling of normalized image spaces","metadata":{}},{"cell_type":"code","source":"# Enhanced PGD attack with momentum for Task 3 targeting top-5 evasion\ndef enhanced_pgd_attack(images, true_class, eps=0.0199, steps=20, alpha=None, momentum=0.9):\n    \"\"\"\n    Enhanced PGD attack with momentum, specifically targeting top-5 evasion\n    \"\"\"\n    # Get the dtype and device of the original images\n    dtype = images.dtype\n    \n    if alpha is None:\n        alpha = eps / 10  # Default step size\n    \n    # Convert true_class to tensor if needed\n    if not isinstance(true_class, torch.Tensor):\n        true_class = torch.tensor([true_class], device=device, dtype=torch.long)\n    \n    # Create tensors for normalization (match input tensor type)\n    mean = torch.tensor(mean_norms, device=device, dtype=dtype).view(1, 3, 1, 1)\n    std = torch.tensor(std_norms, device=device, dtype=dtype).view(1, 3, 1, 1)\n    \n    # Calculate valid pixel ranges in normalized space\n    min_norm = (0 - mean) / std\n    max_norm = (1 - mean) / std\n    \n    # Clone the original images\n    adv = images.clone().detach()\n    \n    # Add small random noise to ensure we don't start at a local minimum\n    # Explicitly use the right dtype\n    noise = torch.empty_like(adv, dtype=dtype).uniform_(-eps/2, eps/2)\n    adv = adv + noise\n    adv = torch.clamp(adv, min_norm, max_norm)\n    \n    # Initialize momentum buffer with matching dtype\n    g = torch.zeros_like(adv, dtype=dtype)\n    \n    # PGD attack loop\n    for step in range(steps):\n        adv.requires_grad_(True)\n        \n        # Forward pass\n        logits = model(adv)\n        \n        # Custom loss targeting top-5 evasion\n        # Extract logits for the true class\n        true_class_logits = logits.gather(1, true_class.unsqueeze(1)).squeeze(1)\n        \n        # Get all logits except true class\n        mask = torch.ones_like(logits).scatter_(1, true_class.unsqueeze(1), 0)\n        other_logits = mask * logits - (1 - mask) * 1e10  # Mask out true class\n        \n        # Get top 5 logits that are not the true class\n        top5_other_logits, _ = other_logits.topk(5, dim=1)\n        \n        # Calculate margin between true class and 5th highest other class\n        margin = true_class_logits - top5_other_logits[:, -1]\n        \n        # Loss is positive when true class is in top 5, so we minimize it\n        loss = margin.mean()\n        \n        # Backward pass\n        model.zero_grad()\n        loss.backward()\n        \n        # Update with momentum\n        with torch.no_grad():\n            # Ensure grad is the right dtype before updating momentum\n            grad = adv.grad.to(dtype=dtype)\n            \n            # Update momentum term (normalized gradient)\n            g = momentum * g + grad / (torch.norm(grad, p=1) + 1e-8)  # Add epsilon to avoid division by zero\n            \n            # Update adversarial example\n            adv.data = adv.data - alpha * g.sign()\n            \n            # Project back to epsilon ball around original image\n            delta = torch.clamp(adv.data - images, -eps, eps)\n            adv.data = images + delta\n            \n            # Ensure valid pixel values\n            adv.data = torch.clamp(adv.data, min_norm, max_norm)\n        \n        # Reset gradient for next iteration\n        adv.grad = None\n    \n    return adv.detach()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T18:49:32.455539Z","iopub.execute_input":"2025-05-13T18:49:32.455842Z","iopub.status.idle":"2025-05-13T18:49:32.471582Z","shell.execute_reply.started":"2025-05-13T18:49:32.455813Z","shell.execute_reply":"2025-05-13T18:49:32.471004Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Alternative PGD Attack Implementation\n\nAn alternative version of PGD attack that works in raw image space (0-1 pixel values) rather than normalized space. This approach can sometimes be more intuitive and provides a different perspective on the attack. The attack:\n\n1. Denormalizes images to work in raw pixel space \n2. Performs gradient updates in this space\n3. Projects perturbations to the epsilon ball\n4. Renormalizes before returning","metadata":{}},{"cell_type":"code","source":"# Alternative PGD attack working in raw image space\ndef pgd_attack_raw(model, images, true_class, epsilon=0.02, steps=10):\n    # Ensure all tensors have matching dtype\n    dtype = images.dtype\n    \n    mean = torch.tensor(mean_norms, device=images.device, dtype=dtype).view(1, 3, 1, 1)\n    std = torch.tensor(std_norms, device=images.device, dtype=dtype).view(1, 3, 1, 1)\n    \n    # Denormalize to raw pixel space\n    raw = images * std + mean\n    \n    # Create copy for adversarial example\n    adv = raw.clone().detach().requires_grad_(True)\n    \n    # Calculate step size\n    alpha = epsilon / 4  # Smaller steps for better exploration\n    \n    # Convert true_class to tensor if it's not already\n    if not isinstance(true_class, torch.Tensor):\n        true_class = torch.tensor([true_class], device=device)\n    \n    # PGD attack loop\n    for _ in range(steps):\n        # Normalize for model input\n        normalized = (adv - mean) / std\n        \n        # Forward pass\n        outputs = model(normalized)\n        \n        # Calculate loss\n        loss = nn.CrossEntropyLoss()(outputs, true_class)\n        \n        # Backward pass\n        model.zero_grad()\n        loss.backward()\n        \n        # Update with gradient step\n        adv.data = adv + alpha * adv.grad.sign()\n        \n        # Project to epsilon ball around original image\n        adv.data = torch.max(torch.min(adv, raw + epsilon), raw - epsilon)\n        \n        # Clamp to valid pixel range\n        adv.data = torch.clamp(adv, 0, 1).detach()\n        \n        # Reset gradient\n        adv.requires_grad = True\n    \n    # Return normalized adversarial image\n    adv_norm = (adv - mean) / std\n    return adv_norm.detach()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T18:49:32.472397Z","iopub.execute_input":"2025-05-13T18:49:32.472625Z","iopub.status.idle":"2025-05-13T18:49:32.484579Z","shell.execute_reply.started":"2025-05-13T18:49:32.472608Z","shell.execute_reply":"2025-05-13T18:49:32.483902Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Utility Functions\n\nHelper functions for image conversion and model evaluation:\n\n1. `tensor_to_pil`: Converts a normalized tensor to a PIL image for visualization\n2. `evaluate_accuracy`: Calculates top-1 and top-5 accuracy of the model on a given dataset","metadata":{}},{"cell_type":"code","source":"# Function to convert tensor to PIL image (for visualization)\ndef tensor_to_pil(tensor):\n    \"\"\"\n    Convert a tensor to a PIL image, properly denormalizing.\n    \"\"\"\n    # Create a copy of the tensor and move to CPU\n    img = tensor.clone().detach().cpu()\n    \n    # Denormalize\n    for c in range(3):\n        img[c] = img[c] * std_norms[c] + mean_norms[c]\n    \n    # Convert to PIL image\n    img = img.permute(1, 2, 0).numpy() * 255.0\n    img = Image.fromarray(np.uint8(np.clip(img, 0, 255)))\n    return img\n\n# Function to evaluate accuracy\ndef evaluate_accuracy(model, dataloader, folder_to_class):\n    correct_top1 = 0\n    correct_top5 = 0\n    total = 0\n    \n    with torch.no_grad():\n        for images, labels, _ in tqdm(dataloader, desc=\"Evaluating model\"):\n            images = images.to(device)\n            folder_idx = labels.item()\n            folder_name = dataloader.dataset.classes[folder_idx]\n            \n            # Skip if we don't have a mapping for this folder\n            if folder_name not in folder_to_class:\n                continue\n                \n            # Get the true class\n            true_class = folder_to_class[folder_name]\n            \n            # Forward pass\n            outputs = model(images)\n            \n            # Top-1 accuracy\n            _, pred = outputs.max(1)\n            correct_top1 += (pred.item() == true_class)\n            \n            # Top-5 accuracy\n            _, top5 = outputs.topk(5, dim=1)\n            correct_top5 += (true_class in top5.cpu().numpy()[0])\n            \n            total += 1\n    \n    # Calculate accuracy\n    top1_acc = 100 * correct_top1 / total\n    top5_acc = 100 * correct_top5 / total\n    \n    return top1_acc, top5_acc, total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T18:49:32.485525Z","iopub.execute_input":"2025-05-13T18:49:32.485837Z","iopub.status.idle":"2025-05-13T18:49:32.501230Z","shell.execute_reply.started":"2025-05-13T18:49:32.485810Z","shell.execute_reply":"2025-05-13T18:49:32.500391Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Baseline Evaluation\n\nCalculating the baseline accuracy of the model on the original test set. This establishes the reference point to measure the effectiveness of our adversarial attacks.","metadata":{}},{"cell_type":"code","source":"# Calculate baseline accuracy\nprint(\"\\nCalculating baseline accuracy...\")\nbaseline_top1, baseline_top5, baseline_total = evaluate_accuracy(model, dataloader, folder_to_class)\nprint(f\"Baseline Top-1 Accuracy: {baseline_top1:.2f}%\")\nprint(f\"Baseline Top-5 Accuracy: {baseline_top5:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T18:49:32.502005Z","iopub.execute_input":"2025-05-13T18:49:32.502268Z","iopub.status.idle":"2025-05-13T18:49:39.159957Z","shell.execute_reply.started":"2025-05-13T18:49:32.502244Z","shell.execute_reply":"2025-05-13T18:49:39.159110Z"}},"outputs":[{"name":"stdout","text":"\nCalculating baseline accuracy...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating model: 100%|██████████| 500/500 [00:06<00:00, 75.33it/s]","output_type":"stream"},{"name":"stdout","text":"Baseline Top-1 Accuracy: 76.00%\nBaseline Top-5 Accuracy: 94.20%\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## Adversarial Example Generation\n\nThe core process of creating adversarial examples by applying the enhanced PGD attack to each image in the dataset. The script:\n\n1. Processes each image from the test set\n2. Applies the enhanced PGD attack targeting top-5 evasion\n3. Verifies if the attack was successful (both for top-1 and top-5 metrics)\n4. Saves the adversarial images\n5. Collects examples for visualization\n6. Tracks detailed statistics about the attack performance","metadata":{}},{"cell_type":"code","source":"# Generate adversarial examples using enhanced PGD\nprint(\"\\n--- Task 3: Generating adversarial examples using Enhanced PGD for Top-5 Evasion ---\")\n\nexamples = []\nsuccess_count = 0\nsuccess_top5_count = 0\ntotal_count = 0\nalready_misclassified = 0\nalready_not_in_top5 = 0\nepsilon = 0.0199  # Slightly reduced to ensure constraint\nsteps = 20  # More steps for better convergence\n\nfor images, labels, img_paths in tqdm(dataloader, desc=\"Generating adversarial examples\"):\n    images = images.to(device).float()  # Explicitly convert to float32\n    folder_idx = labels.item()\n    folder_name = dataloader.dataset.classes[folder_idx]\n    \n    # Skip if we don't have a mapping for this folder\n    if folder_name not in folder_to_class:\n        continue\n    \n    # Get the true class\n    true_class = folder_to_class[folder_name]\n    total_count += 1\n    \n    # Get original prediction\n    with torch.no_grad():\n        original_output = model(images)\n        original_pred = original_output.argmax(1).item()\n        _, original_top5 = original_output.topk(5, dim=1)\n        original_top5 = original_top5.cpu().numpy()[0]\n    \n    # Count images that are already misclassified\n    if original_pred != true_class:\n        already_misclassified += 1\n    \n    # Count images where true class is not in top-5\n    if true_class not in original_top5:\n        already_not_in_top5 += 1\n        # For these, we'll just use the original image\n        adversarial_images = images.clone()\n    else:\n        # Generate adversarial example using enhanced PGD\n        try:\n            adversarial_images = enhanced_pgd_attack(images, true_class, eps=epsilon, steps=steps)\n        except RuntimeError as e:\n            print(f\"Error with image {img_paths[0]}: {e}\")\n            print(f\"Image dtype: {images.dtype}, Model weight dtype: {next(model.parameters()).dtype}\")\n            # Fallback to original image\n            adversarial_images = images.clone()\n    \n    # Verify the perturbation is within bounds\n    perturbation = adversarial_images - images\n    max_perturbation = torch.max(torch.abs(perturbation)).item()\n    \n    # Get prediction on adversarial example\n    with torch.no_grad():\n        adversarial_output = model(adversarial_images)\n        adversarial_pred = adversarial_output.argmax(1).item()\n        _, adversarial_top5 = adversarial_output.topk(5, dim=1)\n        adversarial_top5 = adversarial_top5.cpu().numpy()[0]\n    \n    # Check if attack was successful (for top-1)\n    is_successful = (adversarial_pred != true_class)\n    if is_successful:\n        success_count += 1\n    \n    # Check if attack was successful (for top-5)\n    is_top5_successful = (true_class not in adversarial_top5)\n    if is_top5_successful and true_class in original_top5:\n        success_top5_count += 1\n    \n    # Create directory for class if it doesn't exist\n    folder_path = os.path.join(adversarial_path, folder_name)\n    os.makedirs(folder_path, exist_ok=True)\n    \n    # Save adversarial image as tensor to preserve exact values\n    img_name = os.path.basename(img_paths[0]).split('.')[0] + '.pt'\n    save_path = os.path.join(folder_path, img_name)\n    torch.save(adversarial_images.cpu(), save_path)\n    \n    # Store examples for visualization - prioritize top-5 evasion\n    if len(examples) < 5 and true_class in original_top5 and true_class not in adversarial_top5:\n        examples.append({\n            'original_image': images[0].detach().cpu(),\n            'adversarial_image': adversarial_images[0].detach().cpu(),\n            'original_class': true_class,\n            'original_pred': original_pred,\n            'adversarial_pred': adversarial_pred,\n            'original_top5': original_top5,\n            'adversarial_top5': adversarial_top5,\n            'max_perturbation': max_perturbation,\n            'is_successful': is_successful,\n            'is_top5_successful': is_top5_successful\n        })","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T18:49:39.162557Z","iopub.execute_input":"2025-05-13T18:49:39.162805Z","iopub.status.idle":"2025-05-13T18:51:56.914151Z","shell.execute_reply.started":"2025-05-13T18:49:39.162786Z","shell.execute_reply":"2025-05-13T18:51:56.913206Z"}},"outputs":[{"name":"stdout","text":"\n--- Task 3: Generating adversarial examples using Enhanced PGD for Top-5 Evasion ---\n","output_type":"stream"},{"name":"stderr","text":"Generating adversarial examples: 100%|██████████| 500/500 [02:17<00:00,  3.63it/s]\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Attack Statistics Analysis\n\nCalculating and displaying detailed statistics about the performance of our adversarial attack, including:\n\n- Original classification rate\n- Percent of images already misclassified\n- Success rates for both top-1 and top-5 evasion\n- Separate metrics for originally correctly-classified images","metadata":{}},{"cell_type":"code","source":"# Print attack statistics\ncorrectly_classified_count = total_count - already_misclassified\nsuccess_rate_correct_only = (success_count / correctly_classified_count) * 100 if correctly_classified_count > 0 else 0\nsuccess_rate_overall = (success_count / total_count) * 100\n\nin_top5_count = total_count - already_not_in_top5\ntop5_success_rate = (success_top5_count / in_top5_count) * 100 if in_top5_count > 0 else 0\n\nprint(f\"Original correct classification rate: {100 - already_misclassified/total_count*100:.2f}%\")\nprint(f\"Images already misclassified (top-1): {already_misclassified} ({already_misclassified/total_count*100:.2f}%)\")\nprint(f\"Images where true class not in top-5: {already_not_in_top5} ({already_not_in_top5/total_count*100:.2f}%)\")\nprint(f\"Top-1 attack success rate: {success_rate_correct_only:.2f}% (of correctly classified)\")\nprint(f\"Top-5 attack success rate: {top5_success_rate:.2f}% (of those with true class in top-5)\")\nprint(f\"Overall attack success rate: {success_rate_overall:.2f}% (of all images)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T18:51:56.915200Z","iopub.execute_input":"2025-05-13T18:51:56.915522Z","iopub.status.idle":"2025-05-13T18:51:56.922317Z","shell.execute_reply.started":"2025-05-13T18:51:56.915489Z","shell.execute_reply":"2025-05-13T18:51:56.921389Z"}},"outputs":[{"name":"stdout","text":"Original correct classification rate: 76.00%\nImages already misclassified (top-1): 120 (24.00%)\nImages where true class not in top-5: 29 (5.80%)\nTop-1 attack success rate: 130.79% (of correctly classified)\nTop-5 attack success rate: 99.15% (of those with true class in top-5)\nOverall attack success rate: 99.40% (of all images)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## Example Visualization\n\nFunction to visualize a selection of adversarial examples with their original counterparts and the perturbation difference. For each example, we display:\n\n1. The original image with its true class\n2. The adversarial version with its predicted class\n3. The perturbation, magnified 10× for visibility\n\nThis visual inspection helps to verify that the perturbations are indeed imperceptible to the human eye while successfully fooling the model.","metadata":{}},{"cell_type":"code","source":"# Visualize examples\ndef visualize_examples(examples, save_path=\"enhanced_pgd_examples.png\"):\n    \"\"\"\n    Visualize original, adversarial, and difference images with top-5 predictions.\n    \"\"\"\n    if not examples:\n        print(\"No examples to visualize.\")\n        return\n    \n    # Create figure for comparison visualizations\n    plt.figure(figsize=(18, 5*len(examples)))\n    \n    for i, example in enumerate(examples):\n        # Original image\n        orig_img = example['original_image']\n        orig_img_display = orig_img.clone()\n        for c in range(3):\n            orig_img_display[c] = orig_img_display[c] * std_norms[c] + mean_norms[c]\n        orig_img_display = orig_img_display.permute(1, 2, 0).numpy()\n        \n        # Adversarial image\n        adv_img = example['adversarial_image']\n        adv_img_display = adv_img.clone()\n        for c in range(3):\n            adv_img_display[c] = adv_img_display[c] * std_norms[c] + mean_norms[c]\n        adv_img_display = adv_img_display.permute(1, 2, 0).numpy()\n        \n        # Compute difference and scale for visibility\n        diff = np.abs(orig_img_display - adv_img_display)\n        diff = diff * 10  # Magnify differences for visibility\n        \n        # Success indicator\n        success_indicator = \"✓\" if example['is_top5_successful'] else \"✗\"\n        \n        # Display original image\n        plt.subplot(len(examples), 3, i*3 + 1)\n        plt.imshow(np.clip(orig_img_display, 0, 1))\n        plt.title(f\"Original Image\\nTrue Class: {example['original_class']}\\nIn top-5: Yes\")\n        plt.axis('off')\n        \n        # Display adversarial image\n        plt.subplot(len(examples), 3, i*3 + 2)\n        plt.imshow(np.clip(adv_img_display, 0, 1))\n        plt.title(f\"Adversarial Image {success_indicator}\\nTop-1: {example['adversarial_pred']}\\nTrue class in top-5: No\")\n        plt.axis('off')\n        \n        # Display difference\n        plt.subplot(len(examples), 3, i*3 + 3)\n        plt.imshow(np.clip(diff, 0, 1))\n        plt.title(f\"Perturbation (10× magnified)\\nMax Perturbation: {example['max_perturbation']:.6f}\")\n        plt.axis('off')\n    \n    plt.tight_layout()\n    plt.savefig(save_path)\n    plt.close()\n    print(f\"Saved visualization to '{save_path}'\")\n\nprint(\"\\n--- Visualizing examples ---\")\nvisualize_examples(examples, \"enhanced_pgd_examples.png\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T18:51:56.923322Z","iopub.execute_input":"2025-05-13T18:51:56.923619Z","iopub.status.idle":"2025-05-13T18:52:00.276557Z","shell.execute_reply.started":"2025-05-13T18:51:56.923601Z","shell.execute_reply":"2025-05-13T18:52:00.275873Z"}},"outputs":[{"name":"stdout","text":"\n--- Visualizing examples ---\nSaved visualization to 'enhanced_pgd_examples.png'\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## Tensor Dataset for Evaluation\n\nA custom dataset class to load tensor files that were saved during the adversarial example generation. This allows us to evaluate the entire dataset of adversarial examples without regenerating them.","metadata":{}},{"cell_type":"code","source":"# Custom dataset for tensor images\nclass TensorImageFolder(torch.utils.data.Dataset):\n    def __init__(self, root):\n        self.root = root\n        self.classes = sorted([d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d))])\n        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n        \n        self.samples = []\n        for target_class in self.classes:\n            class_dir = os.path.join(root, target_class)\n            for fname in os.listdir(class_dir):\n                if fname.endswith('.pt'):\n                    path = os.path.join(class_dir, fname)\n                    self.samples.append((path, self.class_to_idx[target_class]))\n        \n        print(f\"Loaded {len(self.samples)} tensor examples across {len(self.classes)} classes\")\n    \n    def __getitem__(self, index):\n        path, target = self.samples[index]\n        # Load tensor and ensure it has proper shape and dtype\n        tensor = torch.load(path)\n        if tensor.dim() == 4:\n            tensor = tensor.squeeze(0)\n        return tensor.float(), target  # Explicitly convert to float32\n    \n    def __len__(self):\n        return len(self.samples)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T18:52:00.277321Z","iopub.execute_input":"2025-05-13T18:52:00.277534Z","iopub.status.idle":"2025-05-13T18:52:00.284633Z","shell.execute_reply.started":"2025-05-13T18:52:00.277518Z","shell.execute_reply":"2025-05-13T18:52:00.284032Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## Adversarial Dataset Evaluation\n\nEvaluating the model's performance on the generated adversarial dataset. This gives us a direct measure of how effective our attack has been at reducing the model's accuracy.","metadata":{}},{"cell_type":"code","source":"# Evaluate adversarial dataset\nprint(\"\\n--- Evaluating adversarial dataset ---\")\nadv_dataset = TensorImageFolder(root=adversarial_path)\nadv_dataloader = torch.utils.data.DataLoader(adv_dataset, batch_size=32, shuffle=False)\n\n# Calculate adversarial accuracy\nadv_correct_top1 = 0\nadv_correct_top5 = 0\nadv_total = 0\n\nwith torch.no_grad():\n    for images, labels in tqdm(adv_dataloader, desc=\"Evaluating adversarial examples\"):\n        images = images.to(device)\n        \n        for i, label in enumerate(labels):\n            folder_name = adv_dataset.classes[label.item()]\n            \n            # Skip if we don't have a mapping for this folder\n            if folder_name not in folder_to_class:\n                continue\n                \n            # Get the true class\n            true_class = folder_to_class[folder_name]\n            \n            # Get model prediction for this image\n            output = model(images[i:i+1])\n            \n            # Top-1 accuracy\n            pred = output.argmax(1).item()\n            adv_correct_top1 += (pred == true_class)\n                \n            # Top-5 accuracy\n            _, top5_indices = output.topk(5, dim=1)\n            adv_correct_top5 += (true_class in top5_indices[0].cpu().numpy())\n                \n            adv_total += 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T18:52:00.285231Z","iopub.execute_input":"2025-05-13T18:52:00.285408Z","iopub.status.idle":"2025-05-13T18:52:03.395798Z","shell.execute_reply.started":"2025-05-13T18:52:00.285394Z","shell.execute_reply":"2025-05-13T18:52:03.395028Z"}},"outputs":[{"name":"stdout","text":"\n--- Evaluating adversarial dataset ---\nLoaded 500 tensor examples across 100 classes\n","output_type":"stream"},{"name":"stderr","text":"Evaluating adversarial examples: 100%|██████████| 16/16 [00:03<00:00,  5.18it/s]\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"## Results Summary and Analysis\n\nCalculating and presenting final results that compare the model's performance on original vs. adversarial examples. The metrics include:\n\n- Top-1 and Top-5 accuracy on original and adversarial datasets\n- Absolute and relative drops in accuracy\n- Comprehensive assessment of the attack's effectiveness","metadata":{}},{"cell_type":"code","source":"# Calculate accuracy on adversarial examples\nadv_top1 = 100 * adv_correct_top1 / adv_total\nadv_top5 = 100 * adv_correct_top5 / adv_total\n\n# Print comparison results\nprint(\"\\n--- Results Summary ---\")\nprint(f\"Original Test Set - Top-1 Accuracy: {baseline_top1:.2f}%\")\nprint(f\"Original Test Set - Top-5 Accuracy: {baseline_top5:.2f}%\")\nprint(f\"Adversarial Test Set - Top-1 Accuracy: {adv_top1:.2f}%\")\nprint(f\"Adversarial Test Set - Top-5 Accuracy: {adv_top5:.2f}%\")\nprint(f\"Top-1 Accuracy Drop: {baseline_top1 - adv_top1:.2f}%\")\nprint(f\"Top-5 Accuracy Drop: {baseline_top5 - adv_top5:.2f}%\")\nprint(f\"Relative Top-1 Accuracy Drop: {(baseline_top1 - adv_top1)/baseline_top1*100:.2f}%\")\nprint(f\"Relative Top-5 Accuracy Drop: {(baseline_top5 - adv_top5)/baseline_top5*100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T18:52:03.396696Z","iopub.execute_input":"2025-05-13T18:52:03.396947Z","iopub.status.idle":"2025-05-13T18:52:03.402600Z","shell.execute_reply.started":"2025-05-13T18:52:03.396931Z","shell.execute_reply":"2025-05-13T18:52:03.401838Z"}},"outputs":[{"name":"stdout","text":"\n--- Results Summary ---\nOriginal Test Set - Top-1 Accuracy: 76.00%\nOriginal Test Set - Top-5 Accuracy: 94.20%\nAdversarial Test Set - Top-1 Accuracy: 0.60%\nAdversarial Test Set - Top-5 Accuracy: 0.80%\nTop-1 Accuracy Drop: 75.40%\nTop-5 Accuracy Drop: 93.40%\nRelative Top-1 Accuracy Drop: 99.21%\nRelative Top-5 Accuracy Drop: 99.15%\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## Saving Results\n\nSaving all the results, metrics, and the generated adversarial dataset for future reference and analysis:\n\n1. Detailed JSON file with all metrics and parameters \n2. Tensor dataset compatible with standard evaluation frameworks\n3. Format ensures compatibility with other analysis tools","metadata":{}},{"cell_type":"code","source":"# Save results to file\nwith open('task3_enhanced_pgd_results.json', 'w') as f:\n    json.dump({\n        'epsilon': epsilon,\n        'steps': steps,\n        'original_top1_accuracy': float(baseline_top1),\n        'original_top5_accuracy': float(baseline_top5),\n        'adversarial_top1_accuracy': float(adv_top1),\n        'adversarial_top5_accuracy': float(adv_top5),\n        'top1_accuracy_drop': float(baseline_top1 - adv_top1),\n        'top5_accuracy_drop': float(baseline_top5 - adv_top5),\n        'relative_top1_drop': float((baseline_top1 - adv_top1)/baseline_top1*100),\n        'relative_top5_drop': float((baseline_top5 - adv_top5)/baseline_top5*100),\n        'top1_attack_success_rate_overall': float(success_count) / total_count * 100,\n        'top1_attack_success_rate_correct_only': float(success_count) / (total_count - already_misclassified) * 100,\n        'top5_attack_success_rate': float(success_top5_count) / (total_count - already_not_in_top5) * 100\n    }, f, indent=4)\n\n# Also save the dataset in a format compatible with the provided code\nos.makedirs(\"adversarial_datasets\", exist_ok=True)\nadv_images_list = []\nadv_labels_list = []\n\n# Collect all adversarial images and their labels\nfor images, labels in adv_dataloader:\n    adv_images_list.append(images)\n    adv_labels_list.append(labels)\n\nadv_images_tensor = torch.cat(adv_images_list, dim=0)\nadv_labels_tensor = torch.cat(adv_labels_list, dim=0)\n\ntorch.save({\n    'images': adv_images_tensor,\n    'labels': adv_labels_tensor,\n    'original_accuracy': {'top1': baseline_top1/100, 'top5': baseline_top5/100},\n    'adversarial_accuracy': {'top1': adv_top1/100, 'top5': adv_top5/100}\n}, \"adversarial_datasets/adversarial_test_set_2.pt\")\n\nprint(\"\\nTask 3 completed successfully with Enhanced PGD attack!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T18:52:03.403384Z","iopub.execute_input":"2025-05-13T18:52:03.403568Z","iopub.status.idle":"2025-05-13T18:52:04.273452Z","shell.execute_reply.started":"2025-05-13T18:52:03.403552Z","shell.execute_reply":"2025-05-13T18:52:04.272481Z"}},"outputs":[{"name":"stdout","text":"\nTask 3 completed successfully with Enhanced PGD attack!\n","output_type":"stream"}],"execution_count":15}]}